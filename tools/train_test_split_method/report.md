Train-test-split
----
### Постановка задачи
Имеются статьи, у каждой из которых есть автор и набор ключевых слов. Хочется сказать, что статьи связаны, если 
у них есть общий автор или общее ключевое слово. Таким образом получим граф, где вершиной является статья, 
а ребром -- 
ключевое слово или автор. 
Хотим разрезать этот граф на трейн и тест, чтобы потерять как можно меньше рёбер.


### Общий подход:
Анализ показал, что по авторам статьи не пересекаются. Значит, будем искать 
пересечения только по ключевым словам.


Для оценки качества разреза будем смотреть распределения следующей величины: 
число вершин в графе, у которых 1 сосед, число вершин в графе, у которых 2 соседа и тд. 

![Formula](source/tex.png?raw=true "Title")


Распределение этой величины должно совпадать при подстановке вместо graph, всего датасета, трейн датасета и
тест датасета.

### Ограничения
1. Есть не очень популярные ключевые слова, которые встречаются 
до десяти раз, есть очень популярные, которые встречаются 50.000 раз.
Те, что встречаются больше 6 раз выкидываем. Не хочется искать похожую статью по тегу 
"математика", хочется более содержательную связь.
2. Оставляем в графе вершины, у которых есть хотя бы 1 сосед. Если соседей нет, тогда возьмем соседа по популярному 
тегу.
3. После анализа компонент связностей оказалось, что у нас одна большая компонента и несколько совсем маленьких. 
Удалим всё, что не в этой компоненте. Если на вход модели придет вершина не из большой компоненты, 
посмотрим, с кем у неё есть связи это можно будет добавить в модель отдельно.

### Основная идея.
Алгоритм: есть N(после всех выбрасываний осталось 1.300.000) вершин в связанном графе. Пойдем его обходить поиском в ширину. Сделаем 0.25N шагов, 
это будет наш ТЕСТ. 
Остановимся, и во всех вершинах, которые мы прошли, оставим все связи внутри этого множества. Назовем
всё, что осталось трейном.
[Анзац](https://ru.wikipedia.org/wiki/%D0%90%D0%BD%D0%B7%D0%B0%D1%86)
следующий: в тесте мы все связи оставили по определению, в трейне должно быть много связей, потому что там 
много вершин.

### Проверка.
Действительно получилось, у нас и в трейне и в тесте осталось относительно столько же вершин с большими 
степенями, сколько и было в начальных данных.
масштаб сильно разный. Так что вот гистограмма для степеней 0-20: <br>
![Histogram1](outputs/hist_0_20.png?raw=true "Title")<br>
Вот гистограмма для 12+:<br>
![Histogram2](outputs/hist_12_.png?raw=true "Title")<br>

### Вопросы, которые могли возникнуть у читателя:
- Почему мы выкинули всю информацию кроме ребер и вершин из графа?
- В будущем в модели будет реализован ембеддинг, Node2vec, который работает, как Word2vec, просто 
ходит по ребрам в случайном порядке, ему больше информации и не надо.

- Почему не применили статистические критерии?
- Дефолтные критерии очень чувствительны на больших выборках, так 
как идеального совпадения распределений добиться невозможно, размер выборки порядка 10^5, а область значений --
целые числа [1, 25], все стандартные критерии говорят, что выборки различны.
